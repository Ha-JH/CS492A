{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edbf77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.utils as vutils\n",
    "from torch import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c69aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07800427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CGAN import CGAN\n",
    "from utils import get_data_loader, generate_images, save_gif\n",
    "from leNet import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "manualSeed = 999\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter settings\n",
    "args = object()\n",
    "args.num_epochs = 10\n",
    "args.ngpu = 1\n",
    "args.ndf = 128\n",
    "args.ngf = 128\n",
    "args.nz = 100\n",
    "args.lr = 0.0002\n",
    "args.beta = 0.5\n",
    "args.nc = 1\n",
    "args.batch_size = 64\n",
    "args.image_size = 64\n",
    "args.num_test_samples = 64\n",
    "args.output_path = \"./results/\"\n",
    "args.fps = 5\n",
    "args.use_fixed = True\n",
    "args.plot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af27c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather MNIST Dataset\n",
    "transform=transforms.Compose([\n",
    "                           transforms.Resize(args.image_size),\n",
    "                           transforms.CenterCrop(args.image_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=0.5, std=0.5)\n",
    "                        #    transforms.Normalize(mean=(0.1307, ), std=(0.3081, )),\n",
    "                       ])    \n",
    "dataset = dset.MNIST(root='./mnist_data/',\n",
    "                       transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size,\n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd416af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if (torch.cuda.is_available() and args.ngpu > 0) else 'cpu')\n",
    "print(\"Using\", cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d806ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7077b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgan = CGAN(ngpu=args.ngpu, device=device, lr=args.lr, nc=args.nc, ndf=args.ndf, nz=args.nz, ngf=args.ngf, beta1=args.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1decf3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    " # initialize other variables\n",
    "num_batches = len(dataloader)\n",
    "fixed_noise = torch.randn(args.num_test_samples, args.nz, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42935196",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = cgan.train(dataloader=dataloader, num_epochs=args.num_epochs, plot=args.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    " #%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "writergif = animation.PillowWriter(fps=30) \n",
    "ani.save(args.output_path+\"fake_cgan.gif\", writer=writergif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86431b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model_path = \"./models/\"\n",
    "filename = \"cgan_Q3.pt\"\n",
    "torch.save(cgan, model_path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model_path = \"./models/\"\n",
    "filename = \"cgan_Q3.pt\"\n",
    "cgan = torch.load(model_path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d933e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2282a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create fake dataset and dataloader\n",
    "fake_dataset, fake_dataloader = cgan.create_dataloader(num_samples=1000, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train classifier\n",
    "model_path = \"./models/\"\n",
    "filename = \"lenet_Q2.pt\"\n",
    "classifier.adv_train(fake_dataloader=fake_dataloader, model_path=model_path, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate classifier on test\n",
    "classifier.evaluate(classifier.test_loader, classifier.dataset_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
